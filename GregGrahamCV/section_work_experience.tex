% YAAC Another Awesome CV LaTeX Template
%
% This template has been downloaded from:
% https://github.com/darwiin/yaac-another-awesome-cv
%
% Author:
% Christophe Roger
%
% Template license:
% CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/)
%Section: Work Experience at the top
\sectionTitle{Work Experience}{\faSuitcase}
%\renewcommand{\labelitemi}{$\bullet$}
\begin{experiences}
  \experience
    {Present}   {Sr. Data Solutions Architect}{Trace3}{}
    {April 2023} {
                      \begin{itemize}
\item Architect and deliver end-to-end Enterprise Data Warehouses using Medallion Architecture (Bronze/Silver/Gold) across Healthcare (HIPAA), Manufacturing, and Marketing domains
\item Design high-performance dimensional models (Star Schema/Kimball) translating complex business logic into actionable intelligence for enterprise clients
\item Engineer near real-time data ingestion pipelines leveraging Snowpipe, Streams \& Tasks, Zero-Copy Cloning, Data Sharing, and Dynamic Tables
\item Implement dbt (Core/Cloud) transformation layers with modular development, automated testing, and CI/CD integration
\item Manage Snowflake FinOps including compute credit optimization, Resource Monitors, and query tuning to minimize Total Cost of Ownership
\item Enforce data security and governance through rigorous RBAC auditing, Network Policies, Dynamic Data Masking, and Row-Level Security for PII/PHI compliance
\item Develop Python-based metrics and custom transformations using Snowpark
                      \end{itemize}
                    }
                    {Snowflake, dbt, Medallion Architecture, Snowpipe, Snowpark, Python, HIPAA, FinOps, CI/CD}
  \emptySeparator
  \experience
    {April 2023}   {BI \& Analytics Lead}{Stoneridge Software}{Enterprise Team}
    {September 2020} {
                      \begin{itemize}
\item Architected near real-time data pipelines using Lakehouse, Databricks, Azure Data Factory, Synapse Analytics, and Serverless pools
\item Designed enterprise data warehouse models for Sales, Finance, Forecast, Inventory, AR, and AP using Kimball dimensional modeling techniques
\item Provided Azure data architecture roadmap strategies to clients covering data security, governance, and development best practices
\item Led the company Center of Excellence for Business Intelligence, preparing internal training and facilitating data governance adoption
\item Created certified Power BI datasets with Power Query and authored DAX measures for executive dashboards introducing OKRs and KPIs
\item Hired and mentored new team members across the enterprise BI practice
                      \end{itemize}
                    }
                    {SQL Server, Azure, Data Lakes, Databricks, Synapse, Power BI, DAX, Power Query, Azure Data Factory}
  \emptySeparator
  \experience
    {August 2020} {Senior Software Engineer | Business Systems Team Lead}{Marshalltown Company}{}
    {July 2007}    {
                      \begin{itemize}
\item Owned Dynamics AX across GL, AR, AP, Production, Master Planning, and Inventory modules plus the corporate data warehouse over 12+ years, building deep cross-functional business knowledge
\item Created a web-based manufacturing execution system (MES) deployed to 100+ factory work cells with real-time Dynamics AX demand integration
\item Implemented procurement and production automation systems with real-time ERP integrations
\item Modeled, built, and verified a comprehensive corporate data warehouse enabling a unified enterprise reporting platform
\item Led SCRUM adoption, CI/CD processes, code reviews, and automated testing and deployment practices across the development team
                      \end{itemize}
                    }
                    {Dynamics AX, SQL, X++, Dimensional Modeling, SSIS, Power BI, Azure DevOps}
  \emptySeparator
  \experience
    {July 2007}     {Lead ETL Developer | Data Warehouse Modeler}{Iowa Medicaid Enterprise}{}
    {November 2003}    {
                      \begin{itemize}
                        \item Designed and implemented modular SSIS packages, stored procedures, and ETL processes for a data warehouse containing billions of rows and terabytes of data
                        \item Architected table and disk partitioning strategies for optimal query performance
                        \item Built incremental processing pipelines from ODS to DW fact and dimension tables with Type 2/Type 3 SCD handling
                        \item Created data quality system for capturing, reporting, and correcting data issues, improving overall data reliability
                      \end{itemize}
                    }
                    {SQL, SSIS, Dimensional Modeling, Healthcare Data, ETL, Performance Tuning}

\end{experiences}
